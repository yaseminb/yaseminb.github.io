<!DOCTYPE html>
<html lang="en">
<body bgcolor="#D7D9E3">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Begin Jekyll SEO tag v2.3.0 -->
<title>Misc | Yasemin Bekiroglu</title>
<meta property="og:title" content="Misc" />
<meta property="og:locale" content="en_US" />
<meta property="og:site_name" content="Yasemin Bekiroglu" />
<script type="application/ld+json">
{"name":null,"description":null,"author":null,"@type":"WebPage","url":"/misc/","publisher":null,"image":null,"headline":"Misc","dateModified":null,"datePublished":null,"sameAs":null,"mainEntityOfPage":null,"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link rel="stylesheet" href="/assets/main.css">
  <link rel="alternate" type="application/rss+xml" title="Yasemin Bekiroglu" href="/feed.xml">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
     <link rel="stylesheet" href="/css/academicons.min.css"/>

</head>


  <body>

    <header class="site-header" role="banner">

  <div class="wrapper">
    
    
    <a class="site-title" rel="author" href="/">Yasemin Bekiro&#287;lu</a>

    
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger">
          
            
            <i class="fa fa-search" style="color:gray" ></i><a class="page-link" href="/research/">Research</a></i>
        
             <i class="fa fa-folder-open" style="color:gray" ></i><a class="page-link" href="/publications/">Publications</a></i>
            
          
            
            
            <i class="fa fa-wrench" style="color:gray" ></i><a class="page-link" href="/workshops/">Workshops</a></i>
            
          
             <i class="fa fa-database" style="color:gray"></i><a class="page-link" href="/data/">Data</a></i>
            
            <i class="fa fa-puzzle-piece" style="color:gray"></i><a class="page-link" href="/misc/">Misc</a></i>
            
          
        </div>
      </nav>
    
  </div>
</header>


    <main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <!--h2 class="post-title"><b><font color=0B1D76>Misc</font></b></h2-->
    <!--h3 id="about"><b><font color=0B1D76>Misc</font></b></h3-->
    <h2><b><font color=0B1D76>Misc</font></b></h2>
  </header>

  <div class="post-content">
    
      <ul style="list-style-type:square;">
  <li>
    <h4 id="invited-talks-seminars-workshop-participation">Invited talks, seminars, workshop participation</h4>
<p align="justify">
   <ul>
<li><p align="justify">"Learning from multi-modal data for perception and action generation", Beijing Institute of Technology, February 6, 2023.</p></li>
     <li><p align="justify">The Future of Tactile Sensing: Applications and Challenges, hosted by Facebook AI Research, November 22-23, 2021.</p></li>
     <li><p align="justify"> A Benchmarking protocol for comparing performances of grasp planning algorithms, IEEE IROS 2021 workshop on Benchmarking of robotic grasping and manipulation: protocols, metrics and data analysis, September 27, 2021.</p></li>
    <li><p align="justify"> Towards robust and goal-oriented robotic grasping and manipulation based on learning from vision and touch, Preferred Networks, 26 May, Tokyo, Japan, 2021.</p></li>
     <li><p align="justify">Research life in robotics and AI, Women in AI, 22 October, 2020.</p></li>
<li><p align="justify">Object shape estimation and modeling combining visual data and tactile exploration, IEEE Conference on Multimedia and Expo (ICME) 2020, Workshop on The Corsmal Challenge: Multi-modal fusion and learning for robotics, 8 July, London, UK.</p></li>
<li><p align="justify">Learning and multi-modal sensing for robotic grasping and manipulation, 30 June, Queen Mary University, London, UK, 2020.</p></li>
<li><p align="justify">Robust grasping and manipulation, NVIDIA Robotics Lab, 23 March, Seattle, USA, 2020.</p></li>
<li><p align="justify">Towards Autonomous Robotic Solutions for Agricultural Robotics, University of Lincoln, 4 March, Lincoln, UK, 2020.</p></li>
<li><p align="justify">AI and multi-modal sensing for Autonomous Robotic Manipulation, University of Birmingham, 3 March, Birmingham, UK, 2020.</p></li>
<li><p align="justify">Robust grasping and manipulation based on sensory data, University College London, 27 February, London, UK, 2020.</p></li>
<li><p align="justify">Learning for grasping and manipulation, Chalmers, 25 Februrary, Sweden, 2020.</p></li>
<li><p align="justify">Towards robust robotic grasping and manipulation applications for industrial tasks, UBTECH, Pasadena, CA, USA, 28 January 2020.</p></li>
<li><p align="justify">Machine Learning for robotics, University of Orebro, Sweden, 3 February 2020.</p></li>
<li><p align="justify">Building Embodied Intelligence that can interact with human environments, Bristol University, UK, July 2019.</p></li>
<li><p align="justify">SARAFun-Smart Assembly Robot with Advanced Functionalities, European Robotics Forum Workshop on Teaching by Demonstration for Industrial Applications, March 2017.</p></li>
<li><p align="justify"> Learning Approaches for Robust Grasping and Manipulation based on Experience, IROS workshop: See, Touch, and Hear: 2nd Workshop on multimodal sensor-based robot control for HRI and soft manipulation, October 2016, South Korea.</p></li>
<li><p align="justify">Learning Approaches for Grasping and Manipulation, Interactive Learning and Robotics Symposium, University of Stuttgart, 14 Dec 2016.</p></li>
<li><p align="justify">Grasping and manipulation based on sensory data, Vicarious, September 2016.</p></li>
<li><p align="justify">Tactile and visual data for grasping, ICRA Workshop on Grasping and Manipulation Datasets, May, 2016.</p></li>
<li><p align="justify">Machine Learning for robotic grasping and manipulation, University of Bath, UK, 5 July 2016. </p></li>
<li><p align="justify">Towards Robust and Goal-oriented Robotic Grasping and Manipulation, Edinburgh University, 19 May 2016, UK.</p></li>
<li><p align="justify">Tutorial on stability and shape estimation with multi-sensory data, The SQUIRREL Winter School,  Feb. 29 - March 4 2016, Austria.</p></li>
<li><p align="justify">Learning to assess grasp stability from vision, touch and proprioception, The workshop on Visual, tactile and force sensing for robot manipulation, the British Machine Vision Association (BMVA) 2015, 9 December 2015, London, UK.</p></li>
<li><p align="justify">Learning from visual and tactile data for robotic grasping and manipulation, University of Birmingham, 8 December, 2015, UK.</p></li>
<li><p align="justify">The Dagstuhl seminar: Multimodal Manipulation Under Uncertainty, 4--9 October, 2015, Germany.</p></li>
<li><p align="justify">Learning from visual and tactile data for grasping and manipulation, The Karlsruhe Institute of Technology, High Performance Humanoid Technologies Lab (H2T), 14 October, 2015, Germany.</p></li>
<li><p align="justify">Shape and stability estimation based on learning from visual and tactile data, Max Planck Institute for Intelligent Systems, the Autonomous Motion Department, 12 October, 2015, Germany.</p></li>
<li><p align="justify">Enhancing Visual Perception of Shape through Tactile Glances, University of Orebro, the Centre of Applied Autonomous Sensor Systems (AASS), 18 May, 2015, Sweden.</p></li>
<li><p align="justify">Perception for grasping and manipulation based on learning and exploration, CSC School Day, KTH, 21 Aug 2015, Sweden.</p></li>
</ul>
    </p>
<hr />

 <ul style="list-style-type:square;">
  <li>
    <h4 id="teaching-and-supervision">Teaching and supervision</h4>

    <p><a href="http://www.csc.kth.se/~yaseminb/el2310.html">Scientific Programming, 2015, KTH</a></p>
    <p>Modelling and Simulation, 2021, 2022, Chalmers</a></p>

    <p>Students:</p>
<p align="justify">
    
      <ul style="list-style-type:square;">
      <li><b>PhD</b></li>
        </ul>
    <ul style="list-style-type:circle;">
       <li>Ahmet Tekden, learning for manipulation from multi-sensory data, main supervision, August 2021 - August 2025, Chalmers</li>
      <li>Christiana Miranda, precision grasping of unknown objects using multimodal data, co-supervision, November 2019 - November 2021, University of Birmingham
      <li>Shahbaz Abdul Khader, learning manipulation skills from experience, co-supervision, January
2017-June 2017, ABB</li>
      <li>Kaiyu Hang, grasping and manipulation, co-supervision, 2014 - 2015, KTH</li>
      <li>Puren Guler, multi-modal perception, co-supervision, 2013 - 2014, KTH</li>
      <li>Johannes Stork, in-hand manipulation, co-supervision, 2014, KTH</li>
          <li>Francisco Vina, grasping and manipulation, co-supervision, 2012 - 2014, KTH</li>
    </ul>
    <ul style="list-style-type:square;">
      <li><b>MSc</b></li>
    </ul>
    <ul style="list-style-type:circle;">
       <li>Yiting Chen, Robust robot manipulation combining vision and touch, main supervision, September 2023 - June 2024, Chalmers</li> 
        <li>Jeffrey Wei, multi-modal object shape exploration, main supervision, November 2022 - August 2023, UCL</li>
       <li>Aishwarya Kanchan, industrial bin-picking, main supervision, December 2022 - August 2023, Chalmers, Volvo</li> 
       <li>Yiyun Xia, industrial bin-picking, main supervision, May - December 2022 - August 2023, Chalmers, Volvo</li> 
       <li>Nils Ingelhag, human-like robot grasping, examiner, January 2023 - August 2023, Chalmers, KTH</li> 
       <li>Rajath Sridhara, mobile manipulation primitives, main supervision, December 2022 - September 2023, Chalmers, ABB</li> 
       <!--li>Razan Ayed, industrial bin-picking, main supervision, January 2023 - September 2023, Chalmers</li--> 
     <li>Tristan Chatelin, mobile manipulation, main supervision, January - September 2022, Chalmers</li> 
        <li>Thanisorn Sriudomporn, optimized pose tracking on edge devices, examiner, January - October 2022, Chalmers</li> 
       <li>Zeid Al Idani, reactive grasping, main supervision, February 2022, Chalmers</li>
      <!--li>Silin Wang, mobile manipulation, main supervision, April 2022, Chalmers</li-->
      <li>Kamiylah Charles, reinforcement learning for grasping, co-supervision, 2021, University College London</li>
      <li>Piotr Tarasiewicz, reinforcement learning for grasping, co-supervision, 2021, University College London</li>
      <li>Gabriela Zarzar Gandler, object shape modelling and understanding using Gaussian Process Implicit Surfaces, main supervision, 2017, ABB</li>
      <li>Kun Yuan, benchmarking for grasping and manipulation, co-supervision, 2016, Uiniversity of Birmingham</li>
  <li>Jesper Karlsson, context based object recognition, main supervision, 2016, KTH</li>
      <li>Lu Wang, learning task-based robotic grasping, with vision, haptics and proprioception, co-supervision, 2012, KTH</li>
      <li>Claudio Giovanoli, potential field based tactile exploration, main supervision, 2011, KTH</li>
    </ul>
    <ul style="list-style-type:square;">
<li><b>Internship and undergraduate thesis</b></li>
    </ul>
    <ul style="list-style-type:circle;">
        <li>Justin Koo, robust robotic grasping utilising touch sensing, main supervision, December 2022 - June 2023, UCL</li> 
       <li>Jingkai Zhou, Jonathan Almgren, Qinghuan Liu, Marcus Degerman, digital twin of a robotic manipulator, main supervision, September 2022 - January 2023, Chalmers</li> 
       <li>Yiting Chen, multi-modal perception, internship, main supervision, November 2022- November 2023, Chalmers</li>
      <li>Yingjie Huang, mobile manipulation, internship, main supervision, 2022, Chalmers</li>
      <li>Sevag Tafnakaji, mobile manipulation, internship, main supervision, 2022, Chalmers</li>
       <li>Rajath Sridhara, reactive grasping, internship, main supervision, 2022, Chalmers</li>
      <li>Lydia Andersson, Sevag Tafnakaji, Lucas Haglund, Simon Widerberg, Linus Haraldsson, Arvid Petersén, mobile manipulation, 
        main supervision, 2022, Chalmers</li>
      <li>Tove Casparsson, Felix Oliv, Johanna Wagne, Caroline Andersson, Daniel Söderqvist, Adam Burman, robot table organization, 
        main supervision, 2022, Chalmers</li>
      <li>Carl folkesson, Erik Carlbaum, Gustav Lindstrom, robot table organization, main supervision, 2021, Chalmers</li>
      <li>Oskar Wangdahl, Mart Waldenstal, Alex Erixon, grasp planning, main supervision, 2021, Chalmers</li>
      <li>Alexey Gorskiy, Henrik Gronback, Hampus Hagstrand, Emil Lukic, Emma Ringstrom, Mattias Wiberg, mobile manipulation, main supervision, 2021, Chalmers</li>
      <li>Henrik Andersson, Badr Aldeen Alhaffar, Elliot Ferning, Jesper Krook, Filippa Kruse, Erik Magnusson, reactive grasping, main supervision, 2021, Chalmers</li>
      <li>Quentin Teixeira, mobile manipulation, internship, main supervision, 2021, Chalmers</li>
      <li>Irem Ozcan, benchmarking grasp planning algorithms, internship, main supervision, 2021, Chalmers</li>
      <li>Lucas Cosier, robot motion planning, co-supervision, BSc thesis, 2021, UCL</li>
      <li>Zuka Murvanidze, shape modeling, co-supervision, BSc thesis, 2021, UCL</li>
      <li>Hampus Andersson, Felix Gustavsson, Valdemar Krona, Olof Olivecrona, Pybullet simulation of manipulators, main supervision, 2021, Chalmers</li>   
      <li>Clara Scherer, object pose tracking, co-supervision, BSc thesis, May-August 2015, KTH</li>
      <li>Judith Butepage, benchmarking for grasping and manipulation, internship, co-supervision, March-May 2015, KTH</li>
      <li>Johannes Exner, shape modeling, main supervision, 2014, KTH</li>
      <li>Mateusz Herczka, robotic software, main supervision, 2014, KTH</li>
      <li>Maren Leithe, using of tactile sensors for object modelling, main supervision, 2010, KTH</li>
      <li>Anais Peyrucq, learning grasp stability based on tactile data, main supervision, 2010, KTH</li>

    </ul>
  </li>
</ul>
          </p>
<hr />

 <ul style="list-style-type:square;">
  <li>
    <h4 id="i-serve-as-a-reviewer-for">I serve as a reviewer for:</h4>

    <p align="justify">International Journal of Humanoid Robotics, IEEE Transactions on Industrial Electronics, 
      IEEE Transactions on Automation Science and Engineering, Big Data, International Journal of Robotics Research (IJRR), 
      IEEE Robotics and Automation Letters (RA-L), Autonomous Robots (AURO), Robotics: Science and Systems (RSS), IEEE Haptics Symposium, 
      IEEE/ASME Transactions on Mechatronics, The International Conference on Computer Vision Systems (ICVS), Advanced Robotics, International Conference on 
      Advanced Robotics (ICAR), IEEE-RAS International Conference on Humanoid Robots, IEEE Transactions on Robotics, Journal of Intelligent and Robotic Systems, 
      IEEE Transactions on Haptics, IEEE/RSJ International Conference on Intelligent Robots and Systems, IEEE International Conference on Robotics and Automation, 
      Conference on Robot Learning, NeurIPS, ICLR, AAAI, ICML.</p>
  </li>
</ul>

    <hr />
    <ul style="list-style-type:square;">
    
 <!--li>
    <h4 id="links">Links:</h4>
<p align="justify">
    <p><a href="http://www.csc.kth.se/capridb/">CapriDB - Capture, Print, Innovate: A Low-Cost Pipeline and Database for Reproducible Manipulation Research</a></p>
    <p><a href="https://data.mendeley.com/datasets/ztkctgvgw6">Visual and Tactile 3D Point Cloud Data from Real Robots for Shape Modeling and Completion</a></p>
      </p>
      </li-->
</ul>
  </div>

</article>

      </div>
    </main>

    <footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <!--h2 class="footer-heading">Dr. Yasemin Bekiroglu</h2-->

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">
            
            </li>
            
          
       
          
         <li>
            <a href="https://scholar.google.com/citations?user=LGgbqWgAAAAJ&hl=en"> 
            <i class="fa fa-google" style="color:gray"></i> google scholar
            </a>
              </li>
          
          <li>
            <!--a href="https://orcid.org/0000-0002-2597-6013 ORCID"-->
            <div itemscope itemtype="https://schema.org/Person"><a itemprop="sameAs" 
  content="https://orcid.org/0000-0002-2597-6013" href="https://orcid.org/0000-0002-2597-6013" 
  target="orcid.widget" rel="me noopener noreferrer" style="vertical-align:top;">
  <img src="https://orcid.org/sites/default/files/images/orcid_16x16.png" style="width:1em;margin-right:.5em;" 
  alt="ORCID iD icon"></a>
            <!--i class="ai ai-orcid"></i>  </a-->
            <a href="https://www.scopus.com/authid/detail.uri?authorId=36661968000">Scopus</a>
              <a href="https://dblp.org/pers/hd/b/Bekiroglu:Yasemin">
             <i class="ai ai-dblp"></i>
             </a>
            <a href="https://www.linkedin.com/in/yaseminbekiroglu/">
            <i class="fa fa-linkedin"></i>
              </a>
              </div>
            </li>
             <li><i class="fa fa-envelope-o"><a class="u-email" href="mailto:yaseminb@chalmers.se"> yaseminb at chalmers.se</i></a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          

          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p></p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
